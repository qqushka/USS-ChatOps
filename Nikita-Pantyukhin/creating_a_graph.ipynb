{"cells":[{"cell_type":"code","execution_count":null,"id":"8bcaa156","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1721115323021,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"8bcaa156"},"outputs":[],"source":["import os  # Для работы с директориями и переменными в окружении\n","import re  # Для работы с регулярными выражениями"]},{"cell_type":"markdown","id":"c86bd367","metadata":{"id":"c86bd367"},"source":["# 1 - Парсинг текста из PDF"]},{"cell_type":"code","execution_count":null,"id":"7b1c4e6f","metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1721115337175,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"7b1c4e6f"},"outputs":[],"source":["# Путь к PDF документов\n","folder_path_to_pdf = \"NPA\""]},{"cell_type":"markdown","id":"9aed4c48","metadata":{"id":"9aed4c48"},"source":["## 1.1 - Использование PyMuPDF (fitz) для получения текста"]},{"cell_type":"code","execution_count":null,"id":"01561e36","metadata":{"executionInfo":{"elapsed":13231,"status":"ok","timestamp":1721115337170,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"01561e36"},"outputs":[],"source":["import fitz  # Для чтения текста из PDF"]},{"cell_type":"code","execution_count":null,"id":"008ff2f9","metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1721115363191,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"008ff2f9"},"outputs":[],"source":["def extract_text_from_pdf(pdf_path):\n","    text = \"\"\n","    try:\n","        with fitz.open(pdf_path) as doc:\n","            for page_num in range(len(doc)):\n","                page = doc.load_page(page_num)\n","                text += page.get_text()\n","    except Exception as e:\n","        print(f\"Ошибка извлечения текста из {pdf_path}: {e}\")\n","\n","    return text"]},{"cell_type":"markdown","id":"bab282b9","metadata":{"id":"bab282b9"},"source":["## 1.2 - Определение оглавления и основного текста документа"]},{"cell_type":"code","execution_count":null,"id":"fdb58c3e","metadata":{},"outputs":[],"source":["def separate_text_from_toc(text):\n","    # Паттерн для разделения документа\n","    match = re.compile(r'(.*?)(?:приказом\\s+ФСТЭК\\s+России|Зарегистрировано\\s+в\\s+Министерстве\\s+юстиции\\s+Российской\\s+Федерации|Одобрен\\s+Советом\\s+Федерации|к\\s+приказу\\s+ФСБ\\s+России|Правительств(?:а|о))(.*)', re.DOTALL).search(text)\n","    if match:\n","        table_of_contents = match.group(1).strip()\n","        main_text = match.group(2).strip()\n","    else:\n","        table_of_contents = \"\"\n","        main_text = text.strip()\n","\n","    return table_of_contents, main_text"]},{"cell_type":"markdown","id":"2e23cb20","metadata":{},"source":["## 1.3 - Очистка текста от лишней и повторяющейся информации"]},{"cell_type":"code","execution_count":null,"id":"cb49440e","metadata":{},"outputs":[],"source":["def clean_text(text):\n","    # Удаление части текста, подготовленной АО \"Кодекс\"\n","    text = re.split(\n","        r'Электронный\\s+текст\\s+документа\\s+подготовлен\\s+АО\\s+\"Кодекс\"\\s+и\\s+сверен\\s+по:',\n","        text,\n","        flags=re.IGNORECASE\n","    )[0]\n","\n","    # Удаление ненужных фраз и информации\n","    text = re.sub(\n","        r'(Документ предоставлен|www\\.consultant\\.ru|КонсультантПлюс|Страница\\s+\\d+\\s+из\\s+\\d+\\s|Дата сохранения: +\\d{2}\\.\\d{2}\\.\\d{4})',\n","        '',\n","        text,\n","        flags=re.IGNORECASE\n","    ).strip()\n","\n","    # Разделение текста на строки и удаление пустых строк\n","    lines_text = [line.strip() for line in text.split('\\n') if line.strip()]\n","\n","    # Удаление подчеркиваний и дефисов\n","    lines_text = [re.sub(r'(_+|-+)', '', line) for line in lines_text]\n","\n","    # Объединение очищенных строк в одну строку\n","    cleaned_text = ' '.join(lines_text)\n","    \n","    return cleaned_text"]},{"cell_type":"markdown","id":"15A_tP52wAvJ","metadata":{"id":"15A_tP52wAvJ"},"source":["## 1.4 - Извлечение идентификационных данных документа\n","- Оранжевое - организация;\n","- Фиолетовое - тип документа;\n","- Голубое - дата и номер документа.\n","\n","<img src=\"figures/document_identification.jpg\"/>"]},{"cell_type":"code","execution_count":null,"id":"r_q-1-bzwAAp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1721130160942,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"r_q-1-bzwAAp","outputId":"3954c1d7-6563-4c85-e9de-3a7d5031192f"},"outputs":[],"source":["def document_identification(text):\n","    # Паттерны для извлечения информации о документе\n","    document_pattern = re.compile(\n","        r\"(ФЕДЕРАЛЬНАЯ\\s+СЛУЖБА\\s+(?:БЕЗОПАСНОСТИ\\s+РОССИЙСКОЙ\\s+ФЕДЕРАЦИИ|ПО\\s+ТЕХНИЧЕСКОМУ\\s+И\\s+ЭКСПОРТНОМУ\\s+КОНТРОЛЮ)|ПРАВИТЕЛЬСТВО\\s+РОССИЙСКОЙ\\s+ФЕДЕРАЦИИ|РОССИЙСКАЯ\\s+ФЕДЕРАЦИЯ|ПРЕЗИДЕНТ\\s+РОССИЙСКОЙ\\s+ФЕДЕРАЦИИ)\\s+\"\n","        r\"((?:ПРИКАЗ|ПОСТАНОВЛЕНИЕ|УКАЗ|ФЕДЕРАЛЬНЫЙ\\s+ЗАКОН))\\s+\"\n","    )\n","    date_number_pattern = re.compile(\n","        r\"(\\d{1,2}\\s+\\w+\\s+\\d{4}\\s+г(?:\\.|ода)?)\\s+(?:N|№)\\s+(\\d+)\"\n","    )\n","\n","    # Примеры:\n","    #   ФЕДЕРАЛЬНАЯ СЛУЖБА БЕЗОПАСНОСТИ РОССИЙСКОЙ ФЕДЕРАЦИИ ПРИКАЗ от 6 мая 2019 года N 196 Об утверждении Требований к средс...\n","    #   ПРАВИТЕЛЬСТВО РОССИЙСКОЙ ФЕДЕРАЦИИ ПОСТАНОВЛЕНИЕ от 8 февраля 2018 г. № 127 МОСКВА Об утверждении Правил категорирован...\n","    #   26 июля 2017 года N 187-ФЗ РОССИЙСКАЯ ФЕДЕРАЦИЯ ФЕДЕРАЛЬНЫЙ ЗАКОН О БЕЗОПАСНОСТИ КРИТИЧЕСКОЙ ИНФОРМАЦИОННОЙ ИНФРАСТРУК...\n","    #   ПРЕЗИДЕНТ РОССИЙСКОЙ ФЕДЕРАЦИИ УКАЗ от 30 марта 2022 г. N 166 О МЕРАХ ПО ОБЕСПЕЧЕНИЮ ТЕХНОЛОГИЧЕСКОЙ НЕЗАВИСИМОСТИ И Б...\n","\n","    # Ищем соответствия в тексте\n","    document_match = document_pattern.search(text)\n","    date_number_match = date_number_pattern.search(text)\n","\n","    if document_match and date_number_match:\n","        organization = document_match.group(1)\n","        document_type = document_match.group(2)\n","        date = date_number_match.group(1)\n","        document_number = date_number_match.group(2)\n","\n","        return {\n","            'organization': organization,\n","            'document_type': document_type,\n","            'date': date,\n","            'document_number': document_number\n","        }\n","    else:\n","        print(\"Не удалось извлечь информацию из текста\")\n","        \n","        return None"]},{"cell_type":"markdown","id":"4dz1wxsR6uQn","metadata":{"id":"4dz1wxsR6uQn"},"source":["## 1.5 - Извлечение заголовков и (под)пунктов"]},{"cell_type":"code","execution_count":null,"id":"e_f1YSS06tRE","metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1721128875634,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"e_f1YSS06tRE"},"outputs":[],"source":["def extract_titles_and_texts(text):\n","    \"\"\"\n","    Извлекает заголовки разделов с римскими цифрами и \"Статья X\" вместе с их текстом.\n","    \"\"\"\n","    roman_pattern = re.compile(r\"(?<=\\b)([IVXLCDM]+\\.\\s+.+?)(?=\\s+[IVXLCDM]+\\.\\s|\\s*\\d+\\.\\s|$)\", re.MULTILINE | re.DOTALL)\n","    article_pattern = re.compile(r\"(?<=\\b)(Статья\\s+\\d+\\.\\s+.+?)(?=\\s+Статья\\s+\\d+\\.\\s|\\s*\\d+\\.\\s|$)\", re.MULTILINE | re.DOTALL)\n","\n","    matches = list(re.finditer(roman_pattern, text)) + list(re.finditer(article_pattern, text))\n","    matches.sort(key=lambda x: x.start())\n","\n","    results = []\n","    for i, match in enumerate(matches):\n","        title = match.group(1).strip()\n","        start_pos = match.end()\n","\n","        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n","        results.append((title, text[start_pos:end_pos].strip()))\n","\n","    return results\n","\n","def get_item_numbers(text):\n","    \"\"\"\n","    Извлекает номера пунктов из текста.\n","    \"\"\"\n","    pattern = re.compile(r\"((?:\\d+\\.)+)\\s*\")\n","    match = pattern.match(text)\n","    if match:\n","        return match.group(1).strip().rstrip('.').split('.')\n","    \n","    return []\n","\n","def extract_subpoints(text, counter_status=['0'], register_counter_status=0):\n","    \"\"\"\n","    Извлекает подпункты из текста и обновляет их счетчики.\n","    \"\"\"\n","    \n","    def update_counters(subpoint_number, counter_status, register_counter_status):\n","        \"\"\"\n","        Обновляет счетчики для подуровней разделов.\n","        \"\"\"\n","        if len(subpoint_number) > len(counter_status):\n","            register_counter_status += 1\n","            counter_status.append('0')\n","        elif len(subpoint_number) < len(counter_status):\n","            register_counter_status -= 1\n","            counter_status.pop()\n","    \n","        counter_status[register_counter_status] = str(int(counter_status[register_counter_status]) + 1)\n","\n","        return counter_status, register_counter_status\n","\n","    subpoint_pattern = re.compile(r\"((?:\\d+\\.)+\\s*.*?)(?=(?:\\d+\\.)+|$)\", re.DOTALL)\n","    matches = re.findall(subpoint_pattern, text)\n","    subpoints = []\n","\n","    for match in matches:\n","        subpoint = match.strip()\n","        subpoint_number = get_item_numbers(subpoint)\n","        if subpoint_number:\n","            counter_status, register_counter_status = update_counters(subpoint_number, counter_status, register_counter_status)\n","            if subpoint_number != counter_status:\n","                if subpoints:\n","                    subpoints[-1] += ' ' + subpoint\n","                    counter_status[register_counter_status] = str(int(counter_status[register_counter_status]) - 1)\n","            else:\n","                subpoints.append(subpoint)\n","\n","    return subpoints, counter_status, register_counter_status"]},{"cell_type":"markdown","id":"faf21fca","metadata":{"id":"faf21fca"},"source":["## 1.6 - Получение информации из PDF"]},{"cell_type":"code","execution_count":null,"id":"6b7ce7b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1721130181365,"user":{"displayName":"qqushka","userId":"02057807309569807044"},"user_tz":-180},"id":"6b7ce7b9","outputId":"cf1b98c8-90bd-4e21-8f5a-ee1cdfa12ec5"},"outputs":[],"source":["def process_pdf_file(pdf_file):\n","    \"\"\"\n","    Обрабатывает PDF файл: извлекает текст, разделяет его на оглавление и основной текст,\n","    идентифицирует документ, извлекает заголовки и их подпункты.\n","    \"\"\"\n","    text = clean_text(extract_text_from_pdf(pdf_file))\n","    doc_info, text = separate_text_from_toc(text)\n","    doc_info = document_identification(doc_info)\n","    titles_and_subpoints = {}\n","\n","    # Поиск заголовков\n","    titles = extract_titles_and_texts(text)\n","\n","    # Инициализация счетчиков подпунктов\n","    counter_subpoints = ['0']\n","    register_counter_status = 0\n","\n","    if titles:\n","        for title, content in titles:\n","            print(f\"\\t({len(title)}) {title[:50]} [..]\")\n","            if 'Статья ' in title:\n","                counter_subpoints = ['0']\n","                register_counter_status = 0\n","            subpoints, counter_subpoints, register_counter_status = extract_subpoints(content, counter_subpoints, register_counter_status)\n","            titles_and_subpoints[title] = subpoints\n","            for subpoint in subpoints:\n","                print(f\"\\t\\t({len(subpoint)}) {subpoint[:50]} [..]\")\n","    else:\n","        subpoints, counter_subpoints, register_counter_status = extract_subpoints(text, counter_subpoints, register_counter_status)\n","        for subpoint in subpoints:\n","            print(f\"\\t({len(subpoint)}) {subpoint[:50]} [..]\")\n","        titles_and_subpoints[\"Без заголовка\"] = subpoints\n","\n","    return {\n","        'doc_info': doc_info,\n","        'titles_and_subpoints': titles_and_subpoints,\n","        'text': text\n","    }\n","\n","def extract_info_from_pdfs(folder_path):\n","    \"\"\"\n","    Извлекает информацию из всех PDF файлов в указанной папке.\n","    \"\"\"\n","    pdf_texts = {}\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".pdf\"):\n","            pdf_file = os.path.join(folder_path, filename)\n","            print(filename)\n","            pdf_data = process_pdf_file(pdf_file)\n","            pdf_texts[filename] = {\n","                'filename': filename,\n","                **pdf_data\n","            }\n","            print('-' * 100)\n","            \n","    return pdf_texts\n","\n","pdf_texts = extract_info_from_pdfs(folder_path_to_pdf)"]},{"cell_type":"markdown","id":"5fe34bae","metadata":{"id":"5fe34bae"},"source":["# 2 - Подготовка, создание графа"]},{"cell_type":"markdown","id":"4446fc3a","metadata":{},"source":["## 2.1 - Подготовка"]},{"cell_type":"markdown","id":"e15645de","metadata":{},"source":["### 2.1.1 - Разделение текста на предложения\n","Для разделения большого текста на предложения используется функция `sent_tokenize` и набор пунктуации из библиотеки `nltk`.\n","\n","Если весь текст это предложение, то он будет разбит на чанки по знакам пунктуации."]},{"cell_type":"code","execution_count":null,"id":"604e54b0","metadata":{},"outputs":[],"source":["import nltk\n","from nltk.tokenize import sent_tokenize"]},{"cell_type":"code","execution_count":null,"id":"6f159631","metadata":{},"outputs":[],"source":["# Набор пунктуации nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"id":"5fe6e52a","metadata":{},"outputs":[],"source":["def split_text_by_punctuation(text, max_chunk_size):\n","    \"\"\"\n","    Разделяет текст примерно в середине, с учетом размера чанка и пунктуации.\n","    \"\"\"\n","    def find_split_index(text, max_chunk_size):\n","        # Найти индекс для разрыва текста около середины, но не превышая max_chunk_size\n","        mid = len(text) // 2\n","        # Найти ближайшую пунктуацию к середине текста\n","        split_points = re.finditer(r'[.,:;!?]\\s*', text)\n","        best_split = None\n","        for point in split_points:\n","            if point.start() <= mid <= point.end():\n","                best_split = point.end()\n","                break\n","            if point.start() < mid:\n","                best_split = point.end()\n","            else:\n","                break\n","            \n","        return best_split if best_split and best_split <= max_chunk_size else mid\n","\n","    chunks = []\n","    while len(text) > max_chunk_size:\n","        split_index = find_split_index(text, max_chunk_size)\n","        chunks.append(text[:split_index].strip())\n","        text = text[split_index:].strip()\n","    \n","    chunks.append(text)\n","\n","    return chunks"]},{"cell_type":"markdown","id":"e24c7c8b","metadata":{},"source":["### 2.1.2 - Суммаризация (Модель IlyaGusev/mbart_ru_sum_gazeta)\n","Если длина предложения превысит размер чанка, то из текста предложения достаётся смысловая выжимка."]},{"cell_type":"markdown","id":"29aae50b","metadata":{},"source":["Пример использования:\n"," - Пусть `article_text` это текст для обработки.\n","\n","`input_ids = tokenizer([article_text], max_length=600, truncation=True, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")`\n","\n","`output_ids = model.generate(input_ids=input_ids, no_repeat_ngram_size=4)[0]`\n","\n","`summary = tokenizer.decode(output_ids, skip_special_tokens=True)`"]},{"cell_type":"code","execution_count":null,"id":"e8f20fd5","metadata":{},"outputs":[],"source":["# Для инициализации модели для суммаризации текста\n","from transformers import MBartTokenizer, MBartForConditionalGeneration"]},{"cell_type":"code","execution_count":null,"id":"f9bf5c53","metadata":{},"outputs":[],"source":["summary_model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n","\n","summary_tokenizer = MBartTokenizer.from_pretrained(summary_model_name)  # Скачивание модели\n","summary_model = MBartForConditionalGeneration.from_pretrained(summary_model_name)  # Загрузка модели\n","summary_model.to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"id":"b9e4cbab","metadata":{},"outputs":[],"source":["def summary_text(text, chunk_size, summary_tokenizer, summary_model):\n","    \"\"\"\n","    Сжимает текст до размера чанка, используя модель суммаризации.\n","    \"\"\"\n","    len_summary = chunk_size + 1\n","    previous_len = len(text)\n","    no_change_count = 0\n","\n","    while len_summary > chunk_size and no_change_count < 3:\n","        input_ids = summary_tokenizer([text], max_length=chunk_size, truncation=True, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n","        output_ids = summary_model.generate(input_ids=input_ids, no_repeat_ngram_size=4)[0]\n","        new_text = summary_tokenizer.decode(output_ids, skip_special_tokens=True)\n","        \n","        if len(new_text) >= previous_len:\n","            no_change_count += 1\n","        else:\n","            no_change_count = 0\n","        \n","        text = new_text\n","        len_summary = len(text)\n","        previous_len = len(text)\n","    \n","    return text"]},{"cell_type":"markdown","id":"86dc3702","metadata":{},"source":["### 2.1.3 - Доступ к LLM через API от HuggingFace (mistralai/Mixtral-8x7B-Instruct-v0.1)\n","Инициализация LLMs для дальнейшего использования этого в функции, которая конвертирует текст в узлы и отношения между ними.\n","\n","Нужен [API ключ](https://huggingface.co/settings/tokens) в режиме `WRITE`.\n","\n","Выбранные модели:\n","1) mistralai/Mistral-7B-Instruct-v0.1\n","2) mistralai/Mistral-7B-Instruct-v0.2\n","3) mistralai/Mistral-7B-Instruct-v0.3\n","4) mistralai/Mixtral-8x7B-Instruct-v0.1\n","5) meta-llama/Meta-Llama-3-8B-Instruct"]},{"cell_type":"code","execution_count":null,"id":"6393053f","metadata":{},"outputs":[],"source":["from getpass import getpass  # Для хранения секретных ключей\n","\n","# Для инициализации и работы с LLM\n","from langchain_community.llms import HuggingFaceEndpoint\n","from langchain_experimental.graph_transformers import LLMGraphTransformer"]},{"cell_type":"code","execution_count":null,"id":"d5f26e32","metadata":{},"outputs":[],"source":["os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass(prompt=\"Введите API ключ от HuggingFaceHub\")"]},{"cell_type":"code","execution_count":null,"id":"84f36199","metadata":{},"outputs":[],"source":["models = [\n","    \"mistralai/Mistral-7B-Instruct-v0.1\",\n","    \"mistralai/Mistral-7B-Instruct-v0.2\",\n","    \"mistralai/Mistral-7B-Instruct-v0.3\",\n","    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n","    \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","]\n","\n","def initialize_transformer(model_id):\n","    hg_llm = HuggingFaceEndpoint(repo_id=model_id)\n","    \n","    return LLMGraphTransformer(llm=hg_llm)"]},{"cell_type":"markdown","id":"d2b7a578","metadata":{},"source":["### 2.1.4 - Работа с Neo4j в AuraDB\n","Граф собирается при использовании Neo4j через облачную версию [AuraDB](https://neo4j.com/cloud/platform/aura-graph-database/)."]},{"cell_type":"code","execution_count":null,"id":"c3ac0ce5","metadata":{},"outputs":[],"source":["from neo4j import GraphDatabase  # Для подключения к среде Neo4j"]},{"cell_type":"code","execution_count":null,"id":"63b0f1e4","metadata":{},"outputs":[],"source":["# Данные для входа в среду Neo4j\n","os.environ[\"NEO4J_URI\"] = \"neo4j+s://8a620302.databases.neo4j.io\"\n","os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n","os.environ[\"NEO4J_PASSWORD\"] = \"CRQWPa75iQbJEfis2yH3DcVevljS17mloAB6Lm3Uoo0\""]},{"cell_type":"code","execution_count":null,"id":"c815c012","metadata":{},"outputs":[],"source":["class Neo4jGraph:\n","    def __init__(self):\n","        self.driver = GraphDatabase.driver(\n","            os.getenv(\"NEO4J_URI\"),\n","            auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n","        )\n","\n","    def close(self):\n","        self.driver.close()\n","\n","    def add_node(self, node_id, node_type, properties=None):\n","        if properties is None:\n","            properties = {}\n","\n","        with self.driver.session() as session:\n","            if properties:\n","                session.run(f\"\"\"\n","                    MERGE (n:{node_type} {{id: $node_id}})\n","                    SET n += $properties\n","                    RETURN n\n","                \"\"\", node_id=node_id, properties=properties)\n","            else:\n","                session.run(f\"\"\"\n","                    MERGE (n:{node_type} {{id: $node_id}})\n","                    RETURN n\n","                \"\"\", node_id=node_id)\n","\n","    def add_relationship(self, source_id, target_id, rel_type):\n","        with self.driver.session() as session:\n","            session.run(\n","                f\"\"\"\n","                MATCH (a {{id: $source_id}})\n","                MATCH (b {{id: $target_id}})\n","                MERGE (a)-[r:{rel_type}]->(b)\n","                \"\"\",\n","                source_id=source_id,\n","                target_id=target_id\n","            )"]},{"cell_type":"markdown","id":"af9776b6","metadata":{},"source":["### 2.1.5 - Перевод текста на русский"]},{"cell_type":"code","execution_count":null,"id":"bacedeca","metadata":{},"outputs":[],"source":["from deep_translator import GoogleTranslator  # Для перевода текста на русский"]},{"cell_type":"code","execution_count":null,"id":"402116e5","metadata":{},"outputs":[],"source":["def translate_to_rus(text):\n","    text = text.replace('_', ' ').replace('-', ' ')\n","    if text.isdigit():\n","        return text\n","    else:\n","        return GoogleTranslator(source='en', target='ru').translate(text)"]},{"cell_type":"markdown","id":"025f4205","metadata":{},"source":["### 2.1.6 - Подготовка ID и типа узла перед добавлением "]},{"cell_type":"code","execution_count":null,"id":"bb61db14","metadata":{},"outputs":[],"source":["def prepare_id_node(text):\n","    text = text.strip()\n","    if text != '':\n","        # Проверяем, соответствует ли строка шаблону заголовка в римском стиле\n","        if re.match(r'^[IVXLCDM]+\\.\\s+', text, re.IGNORECASE):\n","            return text.replace(' ', '_').replace('-', '_')\n","        else:\n","            return translate_to_rus(text).replace(' ', '_').replace('-', '_')\n","    else:\n","        return 'None'\n","    \n","def prepare_type_node(text):\n","    text = text.strip()\n","    if text != '':\n","        # Переводим текст и заменяем пробелы и дефисы на подчеркивания\n","        transformed_text = translate_to_rus(text).replace(' ', '_').replace('-', '_')\n","        # Преобразуем строку так, чтобы первый символ был в верхнем регистре, а остальные в нижнем\n","        transformed_text = transformed_text[0].upper() + transformed_text[1:].lower()\n","        return transformed_text\n","    else:\n","        return 'None'\n"]},{"cell_type":"markdown","id":"b9d1228d","metadata":{},"source":["# 2.2 - Создание графа"]},{"cell_type":"code","execution_count":null,"id":"6b4d8f16","metadata":{},"outputs":[],"source":["from langchain_core.documents import Document  # Для конвертации текста в допустимый формат функции \"convert_to_graph_documents\"\n","import json  # Для логирования успешно завершенных этапов\n","import json_repair  # Для работы функции \"convert_to_graph_documents\""]},{"cell_type":"code","execution_count":null,"id":"WxXy5GVrcAg6","metadata":{"id":"WxXy5GVrcAg6"},"outputs":[],"source":["chunk_size = 500"]},{"cell_type":"code","execution_count":null,"id":"e0ab8f50","metadata":{},"outputs":[],"source":["# Инициализируем граф\n","graph = Neo4jGraph()\n","\n","# Загружаем существующий лог или создаём новый\n","log_file = 'processed_files_log.json'\n","if os.path.exists(log_file):\n","    with open(log_file, 'r', encoding='utf-8') as file:\n","        processed_log = json.load(file)\n","else:\n","    processed_log = {}\n","\n","# Функция для обновления лога\n","def update_log(log_file, filename, paragraph, processed_log):\n","    if filename not in processed_log:\n","        processed_log[filename] = []\n","    processed_log[filename].append(paragraph)\n","    with open(log_file, 'w', encoding='utf-8') as file:\n","        json.dump(processed_log, file, ensure_ascii=False, indent=4)\n","\n","# Функция для добавления базовых узлов\n","def add_basic_nodes(graph, doc):\n","    org_name = doc['organization']\n","    doc_type = doc['document_type']\n","    date = doc['date']\n","    doc_number = doc['document_number']\n","    \n","    org_id = org_name.replace(\" \", \"_\").upper()\n","    graph.add_node(org_id, \"Организация\", {\"название\": org_name})\n","    \n","    graph.add_node(doc_number, \"Документ\", {\n","        \"тип\": doc_type,\n","        \"дата\": date\n","    })\n","    \n","    graph.add_relationship(org_id, doc_number, \"ИЗДАННЫЙ\")\n","\n","# Функция для заполнения графа\n","def filling_in_graph(document, paragraph, graph, models):\n","    global hg_llm_transformer\n","    all_models_failed = True\n","    \n","    for model_id in models:\n","        try:\n","            hg_llm_transformer = initialize_transformer(model_id)\n","            graph_documents = hg_llm_transformer.convert_to_graph_documents(document)\n","            print(f\"\\n({len(graph_documents[0].nodes)}) Nodes: {graph_documents[0].nodes}\")\n","            print(f\"({len(graph_documents[0].relationships)}) Relationships: {graph_documents[0].relationships}\")\n","            \n","            if len(graph_documents[0].nodes) == 0:\n","                print(f\"\\n{model_id} выдала пустой граф.\")\n","                continue\n","            \n","            all_models_failed = False\n","            \n","            for graph_document in graph_documents:\n","                for node in graph_document.nodes:\n","                    graph.add_node(prepare_id_node(node.id), prepare_type_node(node.type))\n","                    graph.add_relationship(prepare_id_node(paragraph), prepare_id_node(node.id), 'СОДЕРЖАНИЕ')\n","                for relationship in graph_document.relationships:\n","                    relationship_source_id = prepare_id_node(relationship.source.id)\n","                    relationship_target_id = prepare_id_node(relationship.target.id)\n","                    if relationship_source_id != relationship_target_id:\n","                        graph.add_relationship(\n","                            relationship_source_id,\n","                            relationship_target_id,\n","                            translate_to_rus(relationship.type).upper().replace(' ', '_')\n","                        )\n","            \n","            print('-' * 100)\n","            break  # Выход из цикла при успешной обработке\n","        except Exception as e:\n","            print(f\"\\nОшибка при использовании модели {model_id}: {e}\")\n","            continue\n","    \n","    if all_models_failed:\n","        print(\"\\nВсе модели выдали плохой результат. Пропуск текста.\")\n","        print('-' * 100)\n","        return False\n","    return True\n","\n","\n","# Основной цикл обработки файлов\n","for filename in pdf_texts:\n","    document_info = pdf_texts[filename]['doc_info']\n","    if document_info is not None:\n","        add_basic_nodes(graph, document_info)\n","        doc_number = document_info['document_number']\n","\n","        for titles_and_subpoints in pdf_texts[filename]['titles_and_subpoints']:\n","            title = f'{titles_and_subpoints.replace(\" \", \"_\").replace(\".\", \"\")}_{doc_number}'\n","\n","            if 'Без_заголовка' not in title:\n","                graph.add_node(prepare_id_node(title), 'Заголовок_пункта')\n","                graph.add_relationship(prepare_id_node(doc_number), prepare_id_node(title), 'СОДЕРЖАНИЕ')\n","\n","            for text in pdf_texts[filename]['titles_and_subpoints'][titles_and_subpoints]:\n","                paragraph = f\"{'_'.join(get_item_numbers(text))}_({prepare_id_node(doc_number)})\"\n","\n","                if filename in processed_log and paragraph in processed_log[filename]:\n","                    print(f\"Пропуск обработанного пункта: {paragraph}\")\n","                    continue\n","\n","                graph.add_node(prepare_id_node(paragraph), 'Пункт')\n","                if 'Без_заголовка' not in title:\n","                    # Привязываем заголовок к (под)пункту\n","                    graph.add_relationship(prepare_id_node(title), prepare_id_node(paragraph), 'СОДЕРЖАНИЕ')\n","                else:\n","                    # Привязываем (под)пункт к номеру документа организации\n","                    graph.add_relationship(prepare_id_node(doc_number), prepare_id_node(paragraph), 'СОДЕРЖАНИЕ')\n","\n","                text = summary_text(text, chunk_size, summary_tokenizer, summary_model)\n","\n","                if len(text) > chunk_size:\n","                    text = sent_tokenize(text)\n","                    if len(text) > 2:\n","                        text = split_text_by_punctuation(text[0], chunk_size)\n","\n","                if isinstance(text, str):\n","                    if filling_in_graph([Document(page_content=text)], paragraph, graph, models):\n","                        update_log(log_file, filename, paragraph, processed_log)\n","                elif isinstance(text, list):\n","                    for text_small in text:\n","                        if len(text_small) > chunk_size:\n","                            text_small = summary_text(text_small, chunk_size, summary_tokenizer, summary_model)\n","                            \n","                        if filling_in_graph([Document(page_content=text_small)], paragraph, graph, models):\n","                            update_log(log_file, filename, paragraph, processed_log)\n","\n","# Закрываем соединение с графом\n","graph.close()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}
