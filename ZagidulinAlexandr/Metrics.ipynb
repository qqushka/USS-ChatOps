{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uOYsgdXdsZKx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Исходный код RAG'a"
      ],
      "metadata": {
        "id": "4pNwWnjhvudg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2VWaBuHfOzb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33879c67-60d6-4411-c1b6-a65f8e35829e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m278.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.1/341.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#Сам добовлял устанавливаемые библиотеки для рассчета метрик\n",
        "!pip install gigachain -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install faiss-cpu -q\n",
        "!pip install gigachain_community -q\n",
        "!pip install gigachain-core -q\n",
        "!pip install pypdf -q\n",
        "!pip install nltk -q\n",
        "!pip install rouge-score -q\n",
        "!pip install transformers datasets -q\n",
        "!pip install torchmetrics -q\n",
        "!pip install evaluate -q\n",
        "!pip install sacrebleu -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from langchain.chat_models import GigaChat"
      ],
      "metadata": {
        "id": "U1D5nkZkO62m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gigachat_api_key = getpass(prompt='Введите API ключ от GigaChat')"
      ],
      "metadata": {
        "id": "3OndaXvWPeBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем языковую модель GigaChat\n",
        "# verify_ssl_certs=False – без использования сертификатов Минцифры\n",
        "llm = GigaChat(credentials=gigachat_api_key, verify_ssl_certs=False, temperature=0.01)"
      ],
      "metadata": {
        "id": "_Vcp2Cp-Pjpo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")"
      ],
      "metadata": {
        "id": "PBVOvlT_R13A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Список путей к документам с ответами на вопросы\n",
        "document_paths_new = [\n",
        "    \"8).pdf\",\n",
        "    \"18).pdf\",\n",
        "    \"24).pdf\",\n",
        "    \"25).pdf\",\n",
        "    \"28).pdf\"\n",
        "]"
      ],
      "metadata": {
        "id": "zwkZ9OENZs-F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка всех документов\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "documents = []\n",
        "for path in document_paths_new:\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents.extend(loader.load())"
      ],
      "metadata": {
        "id": "CwtfFAMZR-cO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение текста на части\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "print(f\"Total documents: {len(split_docs)}\")"
      ],
      "metadata": {
        "id": "TE3VlqMISDTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "VE4DX_2ZSHmg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Если у вас нет видеокарты, укажите 'device': 'cpu'\n",
        "hf_embeddings_model = HuggingFaceEmbeddings(\n",
        "        model_name=\"cointegrated/LaBSE-en-ru\"\n",
        "    )\n",
        "\n",
        "# Создаем FAISS индекс (базу векторов) с полученными эмбеддингами\n",
        "db = FAISS.from_documents(split_docs, hf_embeddings_model)"
      ],
      "metadata": {
        "id": "KNxhfE9kSIyv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание списков вопросов и ответов данных и сгенерированных LLM"
      ],
      "metadata": {
        "id": "5op7ik-YvGWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "pwWiblSjSOhl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())"
      ],
      "metadata": {
        "id": "ayuim02fSQlE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QEarniOvvMQi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df = pd.read_excel(\"q_data.xlsx\", nrows=3).Question\n",
        "answers_df = pd.read_excel(\"q_data.xlsx\", nrows=3).Answer"
      ],
      "metadata": {
        "id": "ZAg8poA9wNJ2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "for e in answers_df:\n",
        "  answers.append(e)\n",
        "\n",
        "questions = []\n",
        "for e in questions_df:\n",
        "  questions.append(e)"
      ],
      "metadata": {
        "id": "JPainw-Q_y1A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = []\n",
        "for e in questions:\n",
        "    message.append(qa_chain({\"query\": e})['result'])"
      ],
      "metadata": {
        "id": "z4u4S_K8x91A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BLEUMetric"
      ],
      "metadata": {
        "id": "r_Nym2tRvDnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вторая попытка реализации (Удачная)"
      ],
      "metadata": {
        "id": "xc3prexJfMlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Попытался написать функцию, что то не работает, скорее всего из-за ссылок, но тратить время не решение проблемы не стал\n",
        "#def qwer(text):\n",
        "#  res = []\n",
        "#  for e in range(len(text)):\n",
        "#    res.append(text[e].split)\n",
        "#  return res"
      ],
      "metadata": {
        "id": "le9bP0CyJ68z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Импортируем функцию вычисления BLEU\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "#Подготовка данных в необходимую форму для вычесления метрики BLEU (приведение к токенизированному виду)\n",
        "translations = []\n",
        "for e in range(len(answers)):\n",
        "  translations.append(answers[e].split())\n",
        "\n",
        "#Оборачиваем ответы в необходимую форму для вычесления метрики BLEU\n",
        "references = [[[ref]] for ref in message]\n",
        "\n",
        "#Костыльное решение, такое, чтобы привелось в необходумую форму\n",
        "references_list = []\n",
        "i = 0\n",
        "for e in range(len(references)):\n",
        "  references_list.append([])\n",
        "  references_list[i].append(references[e][0][0].split())\n",
        "  i = i + 1\n",
        "\n",
        "#Вычисляем BLEU Score\n",
        "bleu_score_corpus = corpus_bleu(references_list, translations)\n",
        "print(\"Corpus BLEU Score: \", bleu_score_corpus)"
      ],
      "metadata": {
        "id": "o2b14fUYypzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Откуда взят код\n",
        "references = [['I', 'love', 'eating', 'ice', 'cream'], ['He', 'enjoys', 'eating', 'cake']]\n",
        "translations = [['I', 'love', 'eating', 'ice', 'cream'], ['He', 'likes', 'to', 'eat', 'cake']]\n",
        "\n",
        "# Create a list of reference lists\n",
        "references_list = [[ref] for ref in references]\n",
        "\n",
        "#Вычисляем BLEU Score\n",
        "bleu_score_corpus = corpus_bleu(references_list, translations)\n",
        "print(\"Corpus BLEU Score: \", bleu_score_corpus)"
      ],
      "metadata": {
        "id": "SetniIL9vNcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROUGE"
      ],
      "metadata": {
        "id": "qT9jmOEX0ilf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rougeL, другой компонент оценки ROUGE, вычисляет самую длинную общую подпоследовательность (LCS) между системными и справочными сводками. В отличие от N-грамм, LCS измеряет максимальную последовательность слов (не обязательно смежных), которые появляются в обоих сводках. Он предлагает более гибкую меру сходства и помогает фиксировать общую информацию, выходящую за рамки строгих дословных совпадений.\n",
        "\n",
        "ROUGE-N - это компонент оценки ROUGE, который количественно определяет перекрытие N-граммов, непрерывных последовательностей из N элементов (обычно слов или символов), между сгенерированной системой сводкой и справочной сводкой. Он дает представление о точности и повторяемости выходных данных системы, учитывая совпадающие N-граммовые последовательности. Разделяется на rouge1, который ищёт совпадения только для отдельных слов и rouge2 - ~ для двух последовательно идущих слов.\n",
        "\n",
        "ROUGE-S фокусируется на пропуск-биграммах. Пропуск-биграмма - это пара слов в предложении, которая допускает пробелы или слова между ними. Этот компонент определяет перекрытие пропусков и биграмм между системным и справочным резюме, позволяя оценить сходство структуры на уровне предложений. Он может фиксировать перефразирующие связи между предложениями и давать представление о способности системы передавать информацию с гибким порядком слов."
      ],
      "metadata": {
        "id": "fJPbubjz1JgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "GqkYq4Kx0um5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
      ],
      "metadata": {
        "id": "JdbDUmeR0xQO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Question', 'Answer', 'LLM_Answer', 'rouge1', 'rouge2', 'rougeL'])\n",
        "for e in range(len(questions)):\n",
        "  candidate_summary = message[e]\n",
        "  reference_summary = answers[e]\n",
        "  r_scores = r_scorer.score(reference_summary, candidate_summary)\n",
        "  new_row = {'Question': questions[e], 'Answer': answers[e], 'LLM_Answer': message[e], 'rouge1': r_scores['rouge1'], 'rouge2': r_scores['rouge2'], 'rougeL': r_scores['rougeL']}\n",
        "  df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
      ],
      "metadata": {
        "id": "Qul5IZRK4HTG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OAyEcWAF4Plh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_scores"
      ],
      "metadata": {
        "id": "rwNGfL3RLXKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Код, на который опирался\n",
        "candidate_summary = \"the cat was found under the bed\"\n",
        "reference_summary = \"the cat was under the bed\"\n",
        "r_scores = r_scorer.score(reference_summary, candidate_summary)\n",
        "for key in r_scores:\n",
        "    print(f'{key}: {r_scores[key]}')\n",
        "r_scores['rouge1']"
      ],
      "metadata": {
        "id": "W0kdkMYn1e9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Семантическая похожесть на основе Sentence Transformers"
      ],
      "metadata": {
        "id": "GX4X-EHbLGKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Опора"
      ],
      "metadata": {
        "id": "uOYsgdXdsZKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "XDaHBfHtLLcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "2vugVpQwLO9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences (already preprocessed)\n",
        "tokens1 = [\"[CLS]\", \"i\", \"like\", \"coding\", \"in\", \"python\", \".\", \"[SEP]\"]\n",
        "tokens2 = [\"[CLS]\", \"python\", \"is\", \"my\", \"favorite\", \"programming\", \"language\", \".\", \"[SEP]\"]\n"
      ],
      "metadata": {
        "id": "u_x4CaZfLQ5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to input IDs\n",
        "input_ids1 = torch.tensor(tokenizer.convert_tokens_to_ids(tokens1)).unsqueeze(0)  # Batch size 1\n",
        "input_ids2 = torch.tensor(tokenizer.convert_tokens_to_ids(tokens2)).unsqueeze(0)  # Batch size 1"
      ],
      "metadata": {
        "id": "49banQfkPJzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the BERT embeddings\n",
        "with torch.no_grad():\n",
        "    t_outputs1 = model(t_input_ids1)\n",
        "    t_outputs2 = model(t_input_ids2)\n",
        "    t_embeddings1 = t_outputs1.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "    t_embeddings2 = t_outputs2.last_hidden_state[:, 0, :]  # [CLS] token\n"
      ],
      "metadata": {
        "id": "RPB2Q7VtWsAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate similarity\n",
        "t_similarity_score = cosine_similarity(t_embeddings1, t_embeddings2)\n",
        "print(\"Similarity Score:\", t_similarity_score)"
      ],
      "metadata": {
        "id": "QqNsxmygW7WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Реализация"
      ],
      "metadata": {
        "id": "izwCASA9EJqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "F7LDlhR0EJTn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepvk/USER-bge-m3\")\n",
        "model = AutoModel.from_pretrained(\"deepvk/USER-bge-m3\")"
      ],
      "metadata": {
        "id": "KbAvNun-EgQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences (already preprocessed)\n",
        "tokens_answer = []\n",
        "for e in range(len(answers)):\n",
        "  tokens_answer.append(answers[e].split())\n",
        "\n",
        "tokens_message = []\n",
        "for e in range(len(message)):\n",
        "  tokens_message.append(message[e].split())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_4IJYo65EgQI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to input IDs\n",
        "input_ids_messages = []\n",
        "input_ids_answers = []\n",
        "\n",
        "for e in range(len(tokens_answer)):\n",
        "  input_ids_messages.append(torch.tensor(tokenizer.convert_tokens_to_ids(tokens_message[e])).unsqueeze(0))  # Batch size 1\n",
        "  input_ids_answers.append(torch.tensor(tokenizer.convert_tokens_to_ids(tokens_answer[e])).unsqueeze(0))  # Batch size 1"
      ],
      "metadata": {
        "id": "VikAGKZpEgQI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the BERT embeddings\n",
        "outputs_messages = []\n",
        "outputs_answers = []\n",
        "embeddings_messages = []\n",
        "embeddings_answers = []\n",
        "with torch.no_grad():\n",
        "    for e in range(len(tokens_answer)):\n",
        "      outputs_messages.append(model(input_ids_messages[e]))\n",
        "      outputs_answers.append(model(input_ids_answers[e]))\n",
        "      embeddings_messages.append(outputs_messages[e].last_hidden_state[:, 0, :])  # [CLS] token\n",
        "      embeddings_answers.append(outputs_answers[e].last_hidden_state[:, 0, :])  # [CLS] token"
      ],
      "metadata": {
        "id": "EjSeiT73EgQI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate similarity\n",
        "similarity_score = []\n",
        "i = 0\n",
        "average_similarity_score = 0\n",
        "df_sim_score = pd.DataFrame(columns=['Answer', 'LLM_Answer', 'Similarity Score'])\n",
        "for e in range(len(tokens_answer)):\n",
        "  similarity_score.append(cosine_similarity(embeddings_messages[e], embeddings_answers[e]))\n",
        "  average_similarity_score += similarity_score[e]\n",
        "  i +=1\n",
        "  new_row = {'Answer': answers[e], 'LLM_Answer': message[e], 'Similarity Score': similarity_score[e]}\n",
        "  df_sim_score = pd.concat([df_sim_score, pd.DataFrame([new_row])], ignore_index=True)\n",
        "print(\"Average Similarity Score = \", average_similarity_score / i)\n",
        "df_sim_score"
      ],
      "metadata": {
        "id": "_anMaa-SEgQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERTScore"
      ],
      "metadata": {
        "id": "P1GGRCvinv4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.text.bert import bert_score\n",
        "preds = message\n",
        "target = answers\n",
        "df_BERTScore = pd.DataFrame(columns=['Answer', 'LLM_Answer', 'Precision', 'Recall', 'F1'])\n",
        "b_score = bert_score(preds=preds , target=target, model_name_or_path=\"deepvk/USER-bge-m3\")\n",
        "for e in range(len(message)):\n",
        "  new_row = {'Answer': answers[e], 'LLM_Answer': message[e], 'Precision': b_score['precision'][e], 'Recall': b_score['recall'][e], 'F1': b_score['f1'][e]}\n",
        "  df_BERTScore = pd.concat([df_BERTScore, pd.DataFrame([new_row])], ignore_index=True)\n",
        "df_BERTScore"
      ],
      "metadata": {
        "id": "FNZ7NgGckMAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#На что опирался\n",
        "from torchmetrics.functional.text.bert import bert_score\n",
        "preds = [\"hello there\", \"general kenobi\", \"я был здесь\"]\n",
        "target = [\"hello there\", \"master kenobi\", \"я был тут\"]\n",
        "q = bert_score(preds, target)\n",
        "q"
      ],
      "metadata": {
        "id": "2ShKNdIsjfry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#METEOR"
      ],
      "metadata": {
        "id": "B7NscdLYfOF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "06_qFQlZg9ho"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = evaluate.load(\"meteor\")"
      ],
      "metadata": {
        "id": "TqjZihesfRPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor_res = []\n",
        "meteor_res_avg = 0\n",
        "i = 0\n",
        "df_meteor = pd.DataFrame(columns=['Answer', 'LLM_Answer', 'meteor_results'])\n",
        "\n",
        "predictions = [[pred] for pred in message]\n",
        "references = [[ref] for ref in answers]\n",
        "\n",
        "for e in range(len(answers)):\n",
        "  meteor_res.append(meteor.compute(predictions=predictions[e], references=references[e]))\n",
        "  meteor_res_avg += meteor_res[e]['meteor']\n",
        "  new_row = {'Answer': answers[e], 'LLM_Answer': message[e], 'meteor_results': meteor_res[e]}\n",
        "  df_meteor = pd.concat([df_meteor, pd.DataFrame([new_row])], ignore_index=True)\n",
        "  i = i + 1\n",
        "\n",
        "meteor_res_avg = meteor_res_avg / i\n",
        "print(meteor_res_avg)\n",
        "df_meteor"
      ],
      "metadata": {
        "id": "MOvsywjMgn0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TER"
      ],
      "metadata": {
        "id": "kEuNHSdJmtsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu"
      ],
      "metadata": {
        "id": "x4eky8USnTsK"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ter = evaluate.load(\"ter\")"
      ],
      "metadata": {
        "id": "O1AqyA11nJGu"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref = [[ref] for ref in answers]\n",
        "results = ter.compute(predictions=message,\n",
        "                        references=ref,\n",
        "                        case_sensitive=True)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "iWMCW6eCq3jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chrF, chrF++"
      ],
      "metadata": {
        "id": "BxZMd3notDqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "sb4-2lQhuLlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref = [[ref] for ref in answers]\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "results = chrf.compute(predictions=message, references=ref)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "kJI2zzVDtYit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}