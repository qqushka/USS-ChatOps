Метрики представленные в блокнотах:
1)BLEU - метрика (Bilingual Evaluation Understudy) — это измерение различий между автоматическим переводом и эталонными переводами того же предложения, выполненными людьми. Эта метрика как раз подходит исходя из данных, которые мы получаем. К итоговому значению применяется корректировка – штраф за краткость.
2)ROUGE (Recall-Oriented Understudy for Gisting Evaluation) – это набор показателей и программный пакет, используемый для оценки задач суммаризации и машинного перевода в NLP. Различные компоненты расписаны в блокноте Metrics.
3)Семантическое сходство текстов — это метрика, которая оценивает насколько похожи два текста с точки зрения смысла. Ответы модели и эталонные значения кодируются в эмбеддинги и сравниваются уже по ним. Для лучших результатов можно поэкспериментировать с моделями AutoTokenizer и AutoModel.
4)BERTScore — это метрика для оценки качества генерации текста, основанная на использовании предобученной модели BERT (Bidirectional Encoder Representations from Transformers). Она предназначена для оценки сходства между сгенерированным текстом и эталонным текстом с использованием векторных представлений слов, полученных с помощью BERT.BERTScore вычисляется на основе косинусного расстояния между эмбеддингами слов в сгенерированном и эталонном текстах, что очень напоминает семантическую близость. Также можно поэкспериментировать с моделями, но настоятельно рекомендую использовать русскоязычные модели.
5)METEOR (Metric for Evaluation of Translation with Explicit ORdering) – основана на подсчете совпадений отдельных слов (unigrams), c расчетом precision, recall, а также обобщающего показателя гармонического среднего (Fmean). Другими словами эта метрика METEOR = BLEU + Семантическое сходство.
6)TER (Translation Edit Rate) - основана на подсчете минимального числа правок, требуемых для приведения машинного перевода в полное соответствие наиболее близкому эталонному переводу. Метрика высчитывает количество правок, которые нужно произвести, чтобы ответ llm стал эталонным.
7)chrF, chrF++ - основана на подсчете совпадений последовательно идущих символов в машинном и эталонном переводах. Не уверен, что смогу написать что то про неё, так как в ней недоразобрался.
8)Ещё находил метрику RIBES, но она разработанная для оценки качества переводов для далеких языков, существенно различных по структуре предложений. Что совсем не подходит для нашей задачи.
9)Не успел реализовать метрику NIST, но она похожа по смыслу на BLEU, но для n-грамм присваивается определённый вес, в зависимости от частоты встречаемости их в языке, на который выполнен перевод. Также отличается от BLEU более мягким штрафом за краткость.
